#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
è¾©è®ºæ•°æ®å…¨é“¾è·¯è´¨é‡è¯„ä¼°è„šæœ¬
- åŸºç¡€ç»Ÿè®¡
- å®Œæ•´æ€§æ£€æŸ¥
- å¤šæ ·æ€§æ£€æµ‹ï¼ˆè¾©é¢˜/è®ºç‚¹ï¼‰
- æœ‰æ•ˆæ€§éªŒè¯ï¼ˆè½»é‡æ¨¡å‹æ¨¡æ‹Ÿï¼‰
- äººå·¥æŠ½æŸ¥
"""

import jsonlines
import os
import re
import random
from collections import Counter
import json

# å¯é€‰ï¼šå®‰è£… sentence-transformers åå¯ç”¨å¤šæ ·æ€§æ£€æµ‹
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    HAS_EMBEDDING = True
except ImportError:
    HAS_EMBEDDING = False
    print("âš ï¸ æœªå®‰è£… sentence-transformersï¼Œè·³è¿‡è¯­ä¹‰å¤šæ ·æ€§æ£€æµ‹")

# å¯é€‰ï¼šæœ‰æ•ˆæ€§éªŒè¯ï¼ˆéœ€é…ç½® DashScope APIï¼‰
USE_VALIDATION = True  # è®¾ä¸º True å¹¶é…ç½® API åå¯ç”¨
if USE_VALIDATION:
    from lm_generation.dashscope_api import call_api


def extract_topic_from_instruction(instr: str) -> str:
    """ä» instruction ä¸­æå–è¾©é¢˜"""
    match = re.search(r"â€œ([^â€]+)â€|'([^']+)â€™", instr)
    if match:
        return match.group(1) or match.group(2)
    return instr


def check_completeness(samples):
    """å®Œæ•´æ€§æ£€æŸ¥"""
    stats = {
        "total": len(samples),
        "empty_output": 0,
        "missing_criteria": 0,
        "role_counts": Counter(),
        "round_distribution": Counter()
    }

    for s in samples:
        instr = s.get("instruction", "")
        output = s.get("output", "").strip()

        # è§’è‰²ç»Ÿè®¡
        if "æ­£æ–¹" in instr:
            role = "æ­£æ–¹"
        elif "åæ–¹" in instr:
            role = "åæ–¹"
        elif "è£åˆ¤" in instr:
            role = "è£åˆ¤"
        else:
            role = "å…¶ä»–"
        stats["role_counts"][role] += 1

        # è½®æ¬¡ç»Ÿè®¡
        round_match = re.search(r"ç¬¬(\d+)è½®", instr)
        if round_match:
            stats["round_distribution"][int(round_match.group(1))] += 1
        elif "ç«‹è®º" in instr:
            stats["round_distribution"][1] += 1

        # ç©ºè¾“å‡º
        if not output:
            stats["empty_output"] += 1

        # åˆ¤å‡†æ£€æŸ¥ï¼ˆä»…å¯¹ç«‹è®ºï¼‰
        if role in ["æ­£æ–¹", "åæ–¹"] and ("ç«‹è®º" in instr or "ç¬¬1è½®" in instr):
            if not re.search(r"[ã€\[]?åˆ¤å‡†[ã€‘\]]?", output):
                stats["missing_criteria"] += 1

    return stats


def check_diversity(samples):
    """å¤šæ ·æ€§æ£€æµ‹"""
    results = {"topic_duplication": 0, "high_similarity_topics": []}

    # æå–è¾©é¢˜
    topics = []
    topic_to_samples = {}
    for s in samples:
        if "ç«‹è®º" in s.get("instruction", "") or "ç¬¬1è½®" in s.get("instruction", ""):
            topic = extract_topic_from_instruction(s["instruction"])
            if topic:
                topics.append(topic)
                topic_to_samples[topic] = s

    if not topics:
        return results

    # ç²¾ç¡®é‡å¤
    exact_dups = len(topics) - len(set(topics))
    results["topic_duplication"] = exact_dups

    # è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if HAS_EMBEDDING and len(topics) > 1:
        unique_topics = list(set(topics))
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        embeddings = model.encode(unique_topics, show_progress_bar=False)
        sim_matrix = cosine_similarity(embeddings)

        high_sim_pairs = []
        for i in range(len(unique_topics)):
            for j in range(i + 1, len(unique_topics)):
                if sim_matrix[i][j] > 0.85:
                    high_sim_pairs.append((unique_topics[i], unique_topics[j], sim_matrix[i][j]))
        results["high_similarity_topics"] = high_sim_pairs

    return results


def validate_effectiveness(samples, sample_size=10):
    """æœ‰æ•ˆæ€§éªŒè¯ï¼ˆè½»é‡æ¨¡å‹æ¨¡æ‹Ÿï¼‰"""
    if not USE_VALIDATION:
        return {"skipped": True}

    validated = 0
    valid_count = 0
    examples = []

    # éšæœºæŠ½æ ·
    sampled = random.sample(samples, min(sample_size, len(samples)))
    for s in sampled:
        if s.get("input") and len(s["input"]) > 50:  # åªéªŒè¯æœ‰ä¸Šä¸‹æ–‡çš„æ ·æœ¬
            try:
                simulated = call_api(
                    prompt=f"{s['input']}\n\n{s['instruction']}",
                    max_tokens=300,
                    temperature=0.3,
                    model="deepseek-v3.2-exp"
                )
                # ç®€å•æ£€æŸ¥ï¼šæ˜¯å¦éç©ºä¸”é•¿åº¦åˆç†
                if simulated and len(simulated.strip()) > 20:
                    valid_count += 1
                validated += 1
                examples.append({
                    "original_output": s["output"][:100],
                    "simulated_output": simulated[:100] if simulated else "None"
                })
            except Exception as e:
                print(f"éªŒè¯å¤±è´¥: {e}")

    return {
        "validated_samples": validated,
        "valid_ratio": valid_count / validated if validated > 0 else 0,
        "examples": examples
    }


def generate_human_review_sample(samples, output_dir="review", sample_size=30):
    """ç”Ÿæˆäººå·¥å®¡æ ¸æ ·æœ¬"""
    os.makedirs(output_dir, exist_ok=True)
    sampled = random.sample(samples, min(sample_size, len(samples)))
    review_path = os.path.join(output_dir, "human_review_sample.jsonl")
    with open(review_path, 'w', encoding='utf-8') as f:
        for item in sampled:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    return review_path


def main(file_path: str):
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    with jsonlines.open(file_path) as f:
        samples = list(f)

    print(f"ğŸ“Š å…¨é“¾è·¯æ•°æ®è´¨é‡è¯„ä¼°: {file_path}")
    print("=" * 50)

    # 1. å®Œæ•´æ€§æ£€æŸ¥
    comp = check_completeness(samples)
    print(f"âœ… æ€»æ ·æœ¬æ•°: {comp['total']}")
    print(f"\nğŸ§® è§’è‰²åˆ†å¸ƒ:")
    for role, count in comp['role_counts'].most_common():
        print(f"  - {role}: {count} ({count/comp['total']*100:.1f}%)")
    
    print(f"\nğŸ“ˆ è½®æ¬¡åˆ†å¸ƒ:")
    for rnd in sorted(comp['round_distribution']):
        print(f"  - ç¬¬{rnd}è½®: {comp['round_distribution'][rnd]}")

    print(f"\nâš ï¸ å®Œæ•´æ€§é—®é¢˜:")
    print(f"  - ç©ºè¾“å‡º: {comp['empty_output']}")
    print(f"  - ç«‹è®ºç¼ºå¤±åˆ¤å‡†: {comp['missing_criteria']}")

    # 2. å¤šæ ·æ€§æ£€æµ‹
    div = check_diversity(samples)
    print(f"\nğŸ” å¤šæ ·æ€§åˆ†æ:")
    print(f"  - ç²¾ç¡®é‡å¤è¾©é¢˜: {div['topic_duplication']}")
    if div.get("high_similarity_topics"):
        print(f"  - é«˜ç›¸ä¼¼åº¦è¾©é¢˜å¯¹: {len(div['high_similarity_topics'])}")
        for t1, t2, sim in div["high_similarity_topics"][:3]:
            print(f"    â€¢ '{t1}' â†” '{t2}' (ç›¸ä¼¼åº¦: {sim:.2f})")

    # 3. æœ‰æ•ˆæ€§éªŒè¯
    val = validate_effectiveness(samples)
    if not val.get("skipped"):
        print(f"\nğŸ§ª æœ‰æ•ˆæ€§éªŒè¯ (æŠ½æ ·{val['validated_samples']}):")
        print(f"  - æ¨¡æ‹ŸæˆåŠŸç‡: {val['valid_ratio']:.1%}")
    else:
        print(f"\nğŸ§ª æœ‰æ•ˆæ€§éªŒè¯: å·²è·³è¿‡ (USE_VALIDATION=False)")

    # 4. ç”Ÿæˆäººå·¥å®¡æ ¸æ ·æœ¬
    review_path = generate_human_review_sample(samples)
    print(f"\nğŸ‘€ äººå·¥å®¡æ ¸æ ·æœ¬å·²ç”Ÿæˆ: {review_path}")

    print("\n" + "=" * 50)
    print("âœ… è¯„ä¼°å®Œæˆï¼")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--file", default="data/training_data.jsonl", help="è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()
    main(args.file)