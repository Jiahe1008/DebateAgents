#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
"""
å®Œæ•´çš„ç§å­æ•°æ®ç”Ÿæˆå™¨ - æ”¯æŒå¤šè½®è¾©è®ºï¼ˆç«‹è®º + å¤šè½®åé©³ + è£åˆ¤ï¼‰
é€‚é… qwen3-max æ¨¡å‹çš„å¼ºç»“æ„åŒ–è¾“å‡ºèƒ½åŠ›
"""
import re
import random
import json
import time
import os
import sys
import traceback
from typing import List, Optional, Dict, Any
from lm_generation.dashscope_api import call_api_with_search
from pathlib import Path


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import client, MODEL_NAME, DATA_DIR
from lm_generation.dashscope_api import call_api, extract_json


class SeedDataGenerator:
    """ç§å­æ•°æ®ç”Ÿæˆå™¨ - æ”¯æŒå¤šè½®è¾©è®ºç”Ÿæˆ"""

    def __init__(self, sleep_between_calls: float = 1.5, default_rounds: int = 2):
        self.sleep = sleep_between_calls
        self.default_rounds = default_rounds  # é»˜è®¤è¾©è®ºè½®æ•°ï¼ˆè‡³å°‘2ï¼‰
        
        # å®šä¹‰ Prompt è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
        self.prompt_dir = os.path.join(os.path.dirname(__file__), '..', 'prompts')
        self.prompt_files = {
            "pro_opening": "æ­£æ–¹é™ˆè¿°-prompt.txt",
            "con_opening": "åæ–¹é™ˆè¿°-prompt.txt",
            "pro_rebuttal": "æ­£æ–¹åé©³-prompt.txt",
            "con_rebuttal": "åæ–¹åé©³-prompt.txt",
            "judge": "è£åˆ¤-prompt.txt"
        }
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        for key, filename in self.prompt_files.items():
            path = os.path.join(self.prompt_dir, filename)
            if not os.path.exists(path):
                raise FileNotFoundError(f"ç¼ºå¤± Prompt æ–‡ä»¶: {path}")

    def _load_prompt(self, key: str) -> str:
        """åŠ è½½æŒ‡å®šè§’è‰²çš„ prompt æ¨¡æ¿"""
        path = os.path.join(self.prompt_dir, self.prompt_files[key])
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()

    def _call_api_json(self, prompt: str, max_tokens: int = 2048, temperature: float = 0.2) -> Optional[dict]:
        """è°ƒç”¨ API å¹¶è¿”å›è§£æåçš„ JSONï¼ˆå¢å¼ºå®¹é”™ï¼‰"""
        print(f"  ğŸ§  è°ƒç”¨ LLM (temp={temperature})...")
        resp = call_api(
            prompt=prompt,
            response_format={"type": "json_object"},
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        if not resp:
            print("  âŒ API è¿”å›ä¸ºç©º")
            return None
            
        # === æ–°å¢ï¼šæå– JSON å—ï¼ˆå…¼å®¹ ```json ... ```ï¼‰===
        text = resp.strip()
        json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', text, re.DOTALL | re.IGNORECASE)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•ç›´æ¥è§£æå…¨æ–‡
            json_str = text

        try:
            parsed = json.loads(json_str, strict=False)
            if isinstance(parsed, dict):
                return parsed
            else:
                print("  âŒ è§£æç»“æœä¸æ˜¯å­—å…¸")
                return None
        except json.JSONDecodeError as e:
            print(f"  âŒ JSON è§£æå¤±è´¥:\n{text[:500]}...\né”™è¯¯: {str(e)}")
            return None


    def _format_opening_side(self, side_data: dict) -> str:
        """å°†ç«‹è®º JSON è½¬ä¸ºè‡ªç„¶è¯­è¨€æ–‡æœ¬"""
        if not side_data:
            return "[å†…å®¹ç¼ºå¤±]"
        parts = []
        if side_data.get("evaluation_criteria"):
            parts.append(f"åˆ¤å‡†ï¼š{side_data['evaluation_criteria']}")
        if side_data.get("definition_of_terms"):
            defs = "ï¼›".join(f"{k}={v}" for k, v in side_data["definition_of_terms"].items())
            parts.append(f"å®šä¹‰ï¼š{defs}")
        args = side_data.get("core_arguments", [])
        if args:
            arg_texts = []
            for arg in args:
                if isinstance(arg, dict):
                    point = arg.get("argument_point", "").strip()
                    evidence = arg.get("evidence_or_example", "").strip()
                    if point:
                        line = f"- {point}"
                        if evidence:
                            line += f"ï¼ˆ{evidence}ï¼‰"
                        arg_texts.append(line)
            if arg_texts:
                parts.append("è®ºç‚¹ï¼š\n" + "\n".join(arg_texts))
        return "\n".join(parts) if parts else str(side_data)
    
    def _format_rebuttal_side(self, rebuttal_data: dict) -> str:
        """å°†åé©³ JSON è½¬ä¸ºè‡ªç„¶è¯­è¨€æ–‡æœ¬"""
        if not rebuttal_data:
            return "[å†…å®¹ç¼ºå¤±]"
        # ä¼˜å…ˆä½¿ç”¨æ‘˜è¦å­—æ®µï¼Œå¦åˆ™æ‹¼æ¥è¦ç‚¹
        summary = rebuttal_data.get("rebuttal_summary") or rebuttal_data.get("main_points_summary", "")
        if summary:
            return str(summary)
        points = rebuttal_data.get("rebuttal_points", [])
        if points:
            texts = []
            for p in points:
                if isinstance(p, dict):
                    pt = p.get("point", "")
                    ref = p.get("refuted_content", "")
                    if pt:
                        line = f"- {pt}"
                        if ref:
                            line += f"ï¼ˆé’ˆå¯¹ï¼š{ref}ï¼‰"
                        texts.append(line)
            return "\n".join(texts) if texts else str(rebuttal_data)
        return str(rebuttal_data)


    def generate_structured_debate(self, topic: str, total_rounds: int = None) -> Optional[dict]:
        """
        ç”Ÿæˆå®Œæ•´å¤šè½®è¾©è®º
        total_rounds: æ€»è½®æ•°ï¼ˆè‡³å°‘2ï¼‰ã€‚ç¬¬1è½®=ç«‹è®ºï¼Œç¬¬2~Nè½®=åé©³ï¼Œæœ€åç”±è£åˆ¤è¯„åˆ¤
        """
        total_rounds = 4  # ğŸ”¥ å¼ºåˆ¶è®¾ä¸º 4 è½®ï¼Œæ— è§†ä¼ å‚

        if total_rounds is None:
            total_rounds = self.default_rounds
        if total_rounds < 2:
            total_rounds = 2

        print(f"\n[{topic}] | ç›®æ ‡è½®æ•°: {total_rounds}")
        debate_history = [] 

        # æ„å»ºè‡ªç„¶è¯­è¨€ä¸Šä¸‹æ–‡çš„å‡½æ•° 
        def build_natural_context(history: list) -> str:
            lines = [f"è¾©é¢˜ï¼š{topic}\n"]
            for rnd in history:
                rn = rnd["round_number"]
                lines.append(f"--- ç¬¬{rn}è½® ---")
                if rn == 1:
                    pro_text = self._format_opening_side(rnd["proponent"])
                    con_text = self._format_opening_side(rnd["opponent"])
                    lines.append(f"ã€æ­£æ–¹ç«‹è®ºã€‘\n{pro_text}")
                    lines.append(f"ã€åæ–¹ç«‹è®ºã€‘\n{con_text}")
                else:
                    pro_text = self._format_rebuttal_side(rnd["proponent"])
                    con_text = self._format_rebuttal_side(rnd["opponent"])
                    lines.append(f"ã€æ­£æ–¹åé©³ã€‘\n{pro_text}")
                    lines.append(f"ã€åæ–¹åé©³ã€‘\n{con_text}")
            return "\n\n".join(lines).strip()

        # === ç¬¬1è½®ï¼šåŒæ–¹ç«‹è®º ===
        print("  ğŸ“¢ ç¬¬1è½®ï¼šç«‹è®ºé˜¶æ®µ")
        pro_opening_prompt = self._load_prompt("pro_opening").replace("{topic}", topic)
        con_opening_prompt = self._load_prompt("con_opening").replace("{topic}", topic)

        pro_stmt = self._call_api_json(pro_opening_prompt, temperature=0.2)
        if not pro_stmt:
            return None
        time.sleep(self.sleep)

        con_stmt = self._call_api_json(con_opening_prompt,temperature=0.2)
        if not con_stmt:
            return None
        time.sleep(self.sleep)

        round1 = {
            "round_number": 1,
            "proponent": pro_stmt,
            "opponent": con_stmt
        }
        debate_history.append(round1)

        pro_reb_prompt_template = self._load_prompt("pro_rebuttal")
        con_reb_prompt_template = self._load_prompt("con_rebuttal")

        # === ç¬¬2 åˆ° total_rounds è½®ï¼šäº¤æ›¿åé©³ ===
        for rnd in range(2, total_rounds + 1):
            print(f"  ğŸ” ç¬¬{rnd}è½®ï¼šåé©³é˜¶æ®µ")
            last_round = debate_history[-1]

            # è·å–é¦–è½®ä¿¡æ¯ï¼ˆç”¨äºæ³¨å…¥åˆ¤å‡†å’Œå®šä¹‰ï¼‰
            initial_pro = debate_history[0]["proponent"]
            initial_con = debate_history[0]["opponent"]

            pro_criteria = initial_pro.get("evaluation_criteria", "æœªæ˜ç¡®")
            con_criteria = initial_con.get("evaluation_criteria", "æœªæ˜ç¡®")

            # æå–å®šä¹‰ï¼ˆå‡è®¾æ˜¯ dictï¼‰
            def format_defs(defs_dict):
                if not isinstance(defs_dict, dict):
                    return "æœªæä¾›"
                return "ï¼›".join(f"{k}ï¼š{v}" for k, v in defs_dict.items()) if defs_dict else "æœªæä¾›"

            pro_defs = format_defs(initial_pro.get("definition_of_terms"))
            con_defs = format_defs(initial_con.get("definition_of_terms"))

            # æ„å»ºå®Œæ•´å†å²æ–‡æœ¬
            full_history_text = build_natural_context(debate_history)

            # ä½¿ç”¨æ¨¡æ¿å‰¯æœ¬
            pro_reb_prompt = pro_reb_prompt_template
            con_reb_prompt = con_reb_prompt_template

            # æ­£æ–¹å›åº”åæ–¹ä¸Šä¸€è½®
            pro_reb_prompt = pro_reb_prompt.replace("{topic}", topic)
            pro_reb_prompt = pro_reb_prompt.replace("{round_number}", str(rnd))
            pro_reb_prompt = pro_reb_prompt.replace("{proponent_initial_criteria}", pro_criteria)
            pro_reb_prompt = pro_reb_prompt.replace("{proponent_initial_definitions}", pro_defs)
            pro_reb_prompt = pro_reb_prompt.replace("{full_debate_history}", full_history_text)

            pro_resp = self._call_api_json(pro_reb_prompt,temperature=0.3)
            if not pro_resp:
                print("  âš ï¸ æ­£æ–¹åé©³å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
                break
            time.sleep(self.sleep)

            # åæ–¹å›åº”æ­£æ–¹æœ¬è½®
            con_reb_prompt = con_reb_prompt.replace("{topic}", topic)
            con_reb_prompt = con_reb_prompt.replace("{round_number}", str(rnd))
            con_reb_prompt = con_reb_prompt.replace("{opponent_initial_criteria}", con_criteria)
            con_reb_prompt = con_reb_prompt.replace("{opponent_initial_definitions}", con_defs)
            con_reb_prompt = con_reb_prompt.replace("{full_debate_history}", full_history_text)

            con_resp = self._call_api_json(con_reb_prompt,temperature=0.3)
            if not con_resp:
                print("  âš ï¸ åæ–¹åé©³å¤±è´¥ï¼Œè·³è¿‡æœ¬è½®")
                break
            time.sleep(self.sleep)

            debate_history.append({
                "round_number": rnd,
                "proponent": pro_resp,
                "opponent": con_resp
            })

        # === è£åˆ¤è¯„åˆ¤ ===
        print("  âš–ï¸ è£åˆ¤è¯„åˆ¤é˜¶æ®µ")
        actual_rounds = len(debate_history)

        # è·å–é¦–è½®ä¿¡æ¯ç”¨äºè£åˆ¤æç¤º
        initial_pro = debate_history[0]["proponent"]
        initial_con = debate_history[0]["opponent"]
        pro_criteria = initial_pro.get("evaluation_criteria", "æœªæ˜ç¡®")
        con_criteria = initial_con.get("evaluation_criteria", "æœªæ˜ç¡®")

        def format_defs(defs_dict):
            if not isinstance(defs_dict, dict):
                return "æœªæä¾›"
            return "ï¼›".join(f"{k}ï¼š{v}" for k, v in defs_dict.items()) if defs_dict else "æœªæä¾›"
        
        pro_defs = format_defs(initial_pro.get("definition_of_terms"))
        con_defs = format_defs(initial_con.get("definition_of_terms"))
        
        full_history_text = build_natural_context(debate_history)

        judge_prompt = self._load_prompt("judge")
        judge_prompt = judge_prompt.replace("{topic}", topic)
        judge_prompt = judge_prompt.replace("{total_rounds}", str(actual_rounds))
        judge_prompt = judge_prompt.replace("{proponent_initial_criteria}", pro_criteria)
        judge_prompt = judge_prompt.replace("{proponent_initial_definitions}", pro_defs)
        judge_prompt = judge_prompt.replace("{opponent_initial_criteria}", con_criteria)
        judge_prompt = judge_prompt.replace("{opponent_initial_definitions}", con_defs)
        judge_prompt = judge_prompt.replace("{full_debate_natural_text}", full_history_text)  

        judgment = self._call_api_json(judge_prompt, temperature=0.1)
        if not judgment:
            return None

        return {
            "topic": topic,
            "total_rounds": actual_rounds,
            "debate_history": debate_history,
            "judgment": judgment,
            "proponent": debate_history[0]["proponent"],
            "opponent": debate_history[0]["opponent"]
        }

    def generate_debate_topics(self, num_topics: int = 10, existing_topics: Optional[List[str]] = None) -> List[str]:
        """ä»åŒç›®å½• debate_topics.txt è¯»å–è¾©é¢˜ï¼ˆå‡è®¾å·²ç”± evaluate_topics.py æ¸…æ´—ï¼‰"""
        if existing_topics is None:
            existing_topics = []

        topics_file = Path(__file__).parent / "debate_topics.txt"
        if not topics_file.exists():
            raise FileNotFoundError(f"âŒ è¯·å…ˆåˆ›å»ºå¹¶æ¸…æ´— {topics_file}ï¼ˆè¿è¡Œ evaluate_topics.pyï¼‰")

        # ä»…è¯»å–éç©ºã€éæ³¨é‡Šè¡Œ
        with open(topics_file, 'r', encoding='utf-8') as f:
            topics = [
                line.strip()
                for line in f
                if line.strip() and not line.strip().startswith('#')
            ]

        # å¯é€‰ï¼šæ’é™¤ä¸ existing_topics å®Œå…¨é‡å¤çš„ï¼ˆç”¨äºå¢é‡ç”Ÿæˆï¼‰
        if existing_topics:
            existing_set = set(existing_topics)
            topics = [t for t in topics if t not in existing_set]

        selected = topics[:num_topics]
        
        print(f"ğŸ“ ä» {topics_file.name} åŠ è½½ {len(selected)} ä¸ªè¾©é¢˜ï¼ˆæœªåšæ¸…æ´—ï¼Œå‡å®šå·²é¢„å¤„ç†ï¼‰")
        return selected


    def generate_review_sample(self, debates, output_dir, sample_size=30):
        """ç”Ÿæˆäººå·¥å®¡æ ¸æ ·æœ¬"""
        os.makedirs(output_dir, exist_ok=True)
        sampled = random.sample(debates, min(sample_size, len(debates)))
        with open(os.path.join(output_dir, "seed_review_sample.jsonl"), 'w', encoding='utf-8') as f:
            for d in sampled:
                f.write(json.dumps(d, ensure_ascii=False) + '\n')

    def generate_seed_dataset(self, num_samples: int = 20, save_path: Optional[str] = None, total_rounds: int = None) -> List[dict]:
        """ä¸»ç”Ÿæˆæµç¨‹"""
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {num_samples} ä¸ªæ ‡å‡†è¾©è®ºæ ·æœ¬ (å¤šè½®æ¨¡å¼, rounds={total_rounds or self.default_rounds})...")
        
        topics = self.generate_debate_topics(num_samples)
        print(f"ğŸ“ è·å¾— {len(topics)} ä¸ªå€™é€‰è¯é¢˜")

        # æ¸…ç©ºä¿å­˜æ–‡ä»¶ï¼ˆé¿å…è¿½åŠ æ—§æ•°æ®ï¼‰
        if save_path:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            open(save_path, 'w').close()  # æ¸…ç©ºæ–‡ä»¶ï¼Œé¿å…ä¸Šæ¬¡æ®‹ç•™
        
        results = []
        for i, topic in enumerate(topics):
            if len(results) >= num_samples:
                break
            print(f"\n--- [{i+1}/{min(num_samples, len(topics))}] ---")
            structured = self.generate_structured_debate(topic, total_rounds=total_rounds)
            if structured:
                results.append(structured)
                print(f"  âœ… æˆåŠŸç”Ÿæˆæ ·æœ¬ {len(results)}")

                if save_path:
                    with open(save_path, 'a', encoding='utf-8') as f:
                        f.write(json.dumps(structured, ensure_ascii=False) + '\n')
                    print(f"  ğŸ’¾ å·²è¿½åŠ ä¿å­˜è‡³: {save_path}")

            else:
                print(f"  âŒ è·³è¿‡è¯é¢˜: {topic}")
            
            if len(results) >= num_samples:
                break
            time.sleep(self.sleep)
        
        # ä¿å­˜
        if save_path and results:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with open(save_path, 'w', encoding='utf-8') as f:
                for item in results:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            print(f"\nğŸ’¾ å·²ä¿å­˜ {len(results)} ä¸ªæ ·æœ¬åˆ°: {save_path}")
            # ç”Ÿæˆå®¡æ ¸æ ·æœ¬
            review_dir = os.path.join(os.path.dirname(save_path), "..", "review")
            self.generate_review_sample(results, review_dir, sample_size=30)

        return results


if __name__ == "__main__":
    generator = SeedDataGenerator(sleep_between_calls=1.5, default_rounds=2)
    data = generator.generate_seed_dataset(
        num_samples=2,
        save_path=os.path.join(DATA_DIR, "seed_dataset.jsonl"),
        total_rounds=4  # å¯åœ¨æ­¤æŒ‡å®šè½®æ•°
    )